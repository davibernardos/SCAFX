{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x216 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEFINITION OF LIBRARIES\n",
    "# ------------------------------------------------\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "# DEFINITION OF PROPRIETARY LIBRARIES \n",
    "# ------------------------------------------------\n",
    "from py_constants import ROOT_INPUT, ROOT_OUTPUT, ROOT_TREE, OUTPUT_FILE\n",
    "from py_constants import METRIC, METHOD\n",
    "from py_constants import LS_TYPES, LS_GROUPS, COLUMN_NAMES\n",
    "from py_constants import T1, T2, T3, T4, T5\n",
    "from py_constants import C1, C2, C3\n",
    "from py_machine_learning import agrupador\n",
    "from py_utilities import studentsIdentifier, columnsIdentifier\n",
    "from py_utilities import outputFilesIdentifier, writeHierarchicalCSV, clearOutputCSV, mkdirOutputFolder\n",
    "from py_utilities import get_printador, get_printador_cab, get_migracao\n",
    "from py_preprocessing import load_file, clear_dir, write_file, write_csv\n",
    "from py_preprocessing import mapear_dir_raiz, read_code, write_join\n",
    "from py_preprocessing import join_tasks, removeLineComment, removeBlockComment\n",
    "\n",
    "#%run py_machine_learning.py\n",
    "%run PY_extrator.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN FUNCTION\n",
    "# ------------------------------------------------\n",
    "def main(classroom=C1, lista=T1, printador=False, num_clusters=4):\n",
    "    \n",
    "    clearOutputCSV(OUTPUT_FILE)\n",
    "    # -------------------------------------------------------------------------------\n",
    "    # (ls_dataset): armazena um dicionÃ¡rio com as features e seus valores \n",
    "    ls_dataset = []\n",
    "            \n",
    "    # files settings\n",
    "    input_folder, output_folder, output_tree, output_cluster = outputFilesIdentifier(ROOT_INPUT, ROOT_OUTPUT, classroom, lista, ROOT_TREE)\n",
    "\n",
    "    # create output folder if do not exist\n",
    "    mkdirOutputFolder(output_folder)\n",
    "            \n",
    "    # join every source code solutions\n",
    "    ls_todos_codigos, ls_name_files = join_tasks(input_folder, output_folder, True)\n",
    "\n",
    "    # -------------------------------------------------------------------------------\n",
    "    # OUTPUT: ls_todos_codigos: [[[cod1-joao], [cod2-joao]], [[cod1-maria], [cod2-maria]]]\n",
    "    for id_aluno, (codigos_aluno, name_codes) in enumerate(zip(ls_todos_codigos, ls_name_files)):\n",
    "        \n",
    "        # O id de aluno inicia em 1\n",
    "        id_aluno += 1\n",
    "        \n",
    "        features = {}             \n",
    "        features = initFeatures(lista)\n",
    " \n",
    "        ##-------------------------------------------------------------------------------                \n",
    "        if (printador):\n",
    "            get_printador_cab(id_aluno)\n",
    "            print(\"n. of source codes: {}\".format(len(codigos_aluno)))\n",
    "                    \n",
    "        ##-------------------------------------------------------------------------------\n",
    "        ## EXTRATOR\n",
    "        for id_cod, (codigo, name_code) in enumerate(zip(codigos_aluno, name_codes)):\n",
    "            \n",
    "            codigo = removeBlockComment(codigo)\n",
    "            codigo = removeLineComment(codigo)\n",
    "            \n",
    "            ## Extraction of the main resources that will be used in subsequent features\n",
    "            ##-------------------------------------------------------------------------------                     \n",
    "            ls_signatures, ls_flags = get_signatures(codigo, LS_TYPES)\n",
    "            ls_functions = get_functions(codigo, LS_TYPES)\n",
    "            ls_calls = get_calls(codigo, LS_TYPES)\n",
    "            ls_func_call = get_func_call(codigo, ls_flags, LS_TYPES)\n",
    "            ##-------------------------------------------------------------------------------    \n",
    "\n",
    "            features = getFeatures(features, lista, codigo, ls_calls, ls_functions, ls_func_call, LS_TYPES)\n",
    "            \n",
    "            if lista == T1:                 \n",
    "                ls_libs = get_calls_libs(codigo, name_codes)\n",
    "                if not ls_libs == \"\":\n",
    "                    for (c, n) in zip(codigos_aluno, name_codes):\n",
    "                        if ls_libs in n:\n",
    "                            ls_signatures, ls_flags = get_signatures(c, LS_TYPES)\n",
    "                            features['NC'] += len(get_calls(codigo, LS_TYPES))\n",
    "                            break\n",
    "                \n",
    "        ##-------------------------------------------------------------------------------\n",
    "        dict_list = {}\n",
    "        dict_list.update(features)                   \n",
    "\n",
    "        ##-------------------------------------------------------------------------------                \n",
    "        if (printador):\n",
    "            get_printador(dict_list)                    \n",
    "     \n",
    "        ls_dataset.append(dict_list)\n",
    "                   \n",
    "    # -------------------------------------------------------------------------------        \n",
    "    # EXTRATOR        \n",
    "    df = pd.DataFrame(ls_dataset)\n",
    "    features_cols = df.keys()\n",
    "            \n",
    "    # students id (eg.: 101, 201 or 301)\n",
    "    start_stud = studentsIdentifier(classroom)\n",
    "            \n",
    "    # get clustering\n",
    "    df, dfx, c = agrupador(df, features_cols, start_stud, output_cluster, num_clusters, METRIC, METHOD, LS_GROUPS)            \n",
    "    \n",
    "    # columns name (eg.: NF, FLC, NP, etc)\n",
    "    columns = columnsIdentifier(lista)\n",
    "    #print(\"\\n>>> EXTRACTED FEATURES: \\n{}\".format(columns))\n",
    "            \n",
    "    # write CSV results\n",
    "    writeHierarchicalCSV(df, columns, OUTPUT_FILE, dfx)\n",
    "    \n",
    "    return (ls_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SCRIPT TO RUN MULTIPLE CLASSROONS AND LISTS\n",
    "# ------------------------------------------------\n",
    "def scriptExec(printador=False):\n",
    "    ls_turmas = {C1}\n",
    "    ls_listas = {T1, T2, T3, T4, T5}\n",
    "    \n",
    "    for turma in sorted(ls_turmas):\n",
    "        for lista in sorted(ls_listas):\n",
    "            main(turma, lista, printador)\n",
    "        break\n",
    "\n",
    "# RUN MULTIPLE LISTS\n",
    "# ------------------------------------------------            \n",
    "#scriptExec()\n",
    "\n",
    "# RUN ONLY ONE LIST\n",
    "# ------------------------------------------------  \n",
    "ls_dataset = main(C1, T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
